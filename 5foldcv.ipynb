{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMwfYCgjR5KJRQmgewAp2y2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ramya2110f/Ramz/blob/master/5foldcv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChEbiuxyaGV0",
        "outputId": "01380603-2e5b-4c90-d682-0391fe75e993"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Accuracy: 0.9167\n",
            "Fold 2 Accuracy: 0.7500\n",
            "Fold 3 Accuracy: 0.8750\n",
            "Fold 4 Accuracy: 0.8333\n",
            "Fold 5 Accuracy: 0.8750\n",
            "\n",
            "Cross-Validation Accuracy Scores:\n",
            "Fold 1: 0.9167\n",
            "Fold 2: 0.7500\n",
            "Fold 3: 0.8750\n",
            "Fold 4: 0.8333\n",
            "Fold 5: 0.8750\n",
            "\n",
            "Average Accuracy: 0.8500\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "import scipy.special\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('/content/Dataset-Mental-Disorders.csv')\n",
        "\n",
        "# Encode categorical labels\n",
        "label_encoder = LabelEncoder()\n",
        "df[\"Expert Diagnose\"] = label_encoder.fit_transform(df[\"Expert Diagnose\"])  # Encode labels\n",
        "\n",
        "# Define features and target\n",
        "X = df.drop(columns=[\"Expert Diagnose\"])\n",
        "y = df[\"Expert Diagnose\"]\n",
        "X = X.apply(lambda col: LabelEncoder().fit_transform(col) if col.dtype == 'object' else col)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Custom focal loss function (Fixed)\n",
        "def custom_focal_loss(preds, dtrain):\n",
        "    labels = dtrain.get_label().astype(int)  # Ensure labels are integers\n",
        "    num_class = preds.shape[1]  # Get number of classes\n",
        "    preds = scipy.special.softmax(preds, axis=1)  # Convert logits to probabilities\n",
        "\n",
        "    gamma = 2.0\n",
        "    alpha = 0.5\n",
        "\n",
        "    p_t = preds[np.arange(len(labels)), labels]\n",
        "    focal_weight = alpha * (1 - p_t) ** gamma\n",
        "\n",
        "    grad = preds.copy()\n",
        "    grad[np.arange(len(labels)), labels] -= 1\n",
        "    grad *= focal_weight[:, np.newaxis]  # Apply focal weight\n",
        "\n",
        "    hess = preds * (1 - preds)  # Hessian for second-order optimization\n",
        "\n",
        "    return grad, hess  # Do NOT flatten, keep the shape as (n_samples, n_classes)\n",
        "\n",
        "# Define parameters for XGBoost\n",
        "params = {\n",
        "    \"objective\": \"multi:softprob\",\n",
        "    \"num_class\": len(np.unique(y)),  # Number of unique classes\n",
        "    \"eval_metric\": \"mlogloss\",  # Multi-class log loss\n",
        "    \"learning_rate\": 0.1,\n",
        "    \"max_depth\": 6,\n",
        "    \"lambda\": 1.0,  # L2 regularization\n",
        "}\n",
        "\n",
        "# Perform Stratified 5-Fold Cross-Validation\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "fold_accuracies = []\n",
        "\n",
        "for fold, (train_idx, test_idx) in enumerate(kf.split(X_scaled, y), 1):\n",
        "    X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]\n",
        "    y_train, y_test = y[train_idx], y[test_idx]\n",
        "\n",
        "    # Create DMatrix for XGBoost\n",
        "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "    dtest = xgb.DMatrix(X_test, label=y_test)\n",
        "\n",
        "    # Train model using custom focal loss\n",
        "    model = xgb.train(params, dtrain, num_boost_round=100, obj=custom_focal_loss)\n",
        "\n",
        "    # Predict and evaluate\n",
        "    y_pred_probs = model.predict(dtest)\n",
        "    y_pred = np.argmax(y_pred_probs, axis=1)  # Get class with highest probability\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    fold_accuracies.append(accuracy)\n",
        "    print(f\"Fold {fold} Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Print all fold accuracies\n",
        "print(\"\\nCross-Validation Accuracy Scores:\")\n",
        "for i, acc in enumerate(fold_accuracies, 1):\n",
        "    print(f\"Fold {i}: {acc:.4f}\")\n",
        "\n",
        "# Print average accuracy\n",
        "print(f\"\\nAverage Accuracy: {np.mean(fold_accuracies):.4f}\")\n",
        "\n",
        "\n"
      ]
    }
  ]
}